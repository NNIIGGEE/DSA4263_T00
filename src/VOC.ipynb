{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/wangyangyi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/wangyangyi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/wangyangyi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/wangyangyi/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "2023-04-13 21:50:00.483229: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import train_SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================CLEANING DATA=========================\n",
      "========================READ RAW DATA=======================\n",
      "=======================LOWERCASE TEXT=======================\n",
      "========================TOKENIZE TEXT=======================\n",
      "=====================REMOVE PUNCTUATION=====================\n",
      "======================REMOVE STOPWORDS======================\n",
      "=====================REMOVE SHORT WORDS=====================\n",
      "==================CONVERT AMAZON.COM TOKENS=================\n",
      "=====================REMOVE CONTRACTIONS====================\n",
      "=====================REMOVE PUNCTUATION=====================\n",
      "========================REMOVE DIGITS=======================\n",
      "======================LEMMATIZE TOKENS======================\n",
      "======================REMOVE DUPLICATES=====================\n",
      "======================APPEND LABELS=========================\n",
      "==================DATA PREPROCESSING DONE===================\n",
      "=======================ORIGINAL TEXT========================\n",
      "0    this is a very healthy dog food. good for thei...\n",
      "1    i've been very pleased with the natural balanc...\n",
      "2    before i was educated about feline nutrition, ...\n",
      "3    my holistic vet recommended this, along with a...\n",
      "4    i bought this coffee because its much cheaper ...\n",
      "Name: Text, dtype: object\n",
      "=====================PREPROCESSED TOKENS====================\n",
      "0    [dog, require, amount, healthy, every, good, f...\n",
      "1    [dog, balance, large, kibble, issue, someone, ...\n",
      "2    [feed, educate, canned, old, good, recently, d...\n",
      "3    [less, benefit, health, vet, find, prefer, cat...\n",
      "4    [expect, less, totally, good, taste, introduci...\n",
      "Name: cleaned, dtype: object\n",
      "============================DONE============================\n",
      "=========================TRAINING MODEL=========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyangyi/Documents/GitHub/DSA4263_T00/src/sentiment_analysis/prep/preprocess.py:346: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df.loc[:,'cleaned2'] = final_df.loc[:,'cleaned'].apply(lambda x: ' '.join(x))\n",
      "2023-04-13 21:50:19.612332: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 4s 55ms/step - loss: 0.6041 - accuracy: 0.7355 - val_loss: 0.5469 - val_accuracy: 0.7401\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 1s 39ms/step - loss: 0.4897 - accuracy: 0.7534 - val_loss: 0.4400 - val_accuracy: 0.7925\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 1s 37ms/step - loss: 0.3090 - accuracy: 0.8863 - val_loss: 0.3373 - val_accuracy: 0.8577\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 1s 39ms/step - loss: 0.1855 - accuracy: 0.9403 - val_loss: 0.2965 - val_accuracy: 0.8806\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 2s 44ms/step - loss: 0.1099 - accuracy: 0.9706 - val_loss: 0.3066 - val_accuracy: 0.8834\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 1s 38ms/step - loss: 0.0660 - accuracy: 0.9860 - val_loss: 0.3417 - val_accuracy: 0.8779\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 1s 37ms/step - loss: 0.0422 - accuracy: 0.9927 - val_loss: 0.3863 - val_accuracy: 0.8779\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 1s 38ms/step - loss: 0.0308 - accuracy: 0.9940 - val_loss: 0.4243 - val_accuracy: 0.8577\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 1s 37ms/step - loss: 0.0244 - accuracy: 0.9954 - val_loss: 0.4088 - val_accuracy: 0.8705\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 1s 36ms/step - loss: 0.0168 - accuracy: 0.9977 - val_loss: 0.4466 - val_accuracy: 0.8669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://da6af549-18c0-4dcc-9d3f-ebaa01949779/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://da6af549-18c0-4dcc-9d3f-ebaa01949779/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can find trained model in trained_models\n",
      "============================DONE============================\n",
      "=========================GETTING PREDICTIONS=========================\n",
      "35/35 [==============================] - 1s 6ms/step\n",
      "=======================LSTM PREDICTIONS========================\n",
      "                                                   Text  predicted\n",
      "1186  i came home from a hot morning in the arizona ...        1.0\n",
      "4765  overall, this mix is okay, but, the sugar cont...        0.0\n",
      "410   these really are good i gave some to other peo...        1.0\n",
      "1945  this is a poor excuse for coffee - even for in...        0.0\n",
      "3848  we sent this basket to my mother in law for mo...        1.0\n",
      "=======================VADER PREDICTIONS========================\n",
      "                                                   Text  predicted\n",
      "1186  i came home from a hot morning in the arizona ...          1\n",
      "4765  overall, this mix is okay, but, the sugar cont...          1\n",
      "410   these really are good i gave some to other peo...          1\n",
      "1945  this is a poor excuse for coffee - even for in...          1\n",
      "3848  we sent this basket to my mother in law for mo...          1\n",
      "=========================DONE=========================\n",
      "======================EVALUATING MODELS======================\n",
      "======================LSTM PERFORMANCE======================\n",
      "Accuracy =  0.8668503213957759\n",
      "Precision =  0.905521472392638\n",
      "ROC AUC =  0.8217739743443607\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74       283\n",
      "           1       0.91      0.92      0.91       806\n",
      "\n",
      "    accuracy                           0.87      1089\n",
      "   macro avg       0.83      0.82      0.83      1089\n",
      "weighted avg       0.87      0.87      0.87      1089\n",
      "\n",
      "======================VADER PERFORMANCE======================\n",
      "Accuracy =  0.7988980716253443\n",
      "Precision =  0.7961654894046418\n",
      "ROC AUC =  0.6325636349288464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.29      0.43       283\n",
      "           1       0.80      0.98      0.88       806\n",
      "\n",
      "    accuracy                           0.80      1089\n",
      "   macro avg       0.81      0.63      0.65      1089\n",
      "weighted avg       0.80      0.80      0.76      1089\n",
      "\n",
      "============================SELECTING BEST MODEL============================\n",
      "LSTM performed better in accuracy\n",
      "LSTM performed better in precision\n",
      "LSTM performed better in ROC AUC\n",
      "LSTM performed better in Recall\n",
      "LSTM performed better in F1 score\n",
      "LSTM is the better model\n",
      "============================DONE============================\n",
      "======================TRAINING SELECTED MODEL ON FULL DATA======================\n",
      "Epoch 1/10\n",
      "35/35 [==============================] - 3s 48ms/step - loss: 0.4778 - accuracy: 0.8912 - val_loss: 2.5228 - val_accuracy: 0.0698\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 1s 39ms/step - loss: 0.3026 - accuracy: 0.9079 - val_loss: 2.1503 - val_accuracy: 0.0698\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 1s 38ms/step - loss: 0.2854 - accuracy: 0.9079 - val_loss: 2.0725 - val_accuracy: 0.0698\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 1s 43ms/step - loss: 0.2066 - accuracy: 0.9107 - val_loss: 1.7968 - val_accuracy: 0.1038\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 1s 38ms/step - loss: 0.1403 - accuracy: 0.9456 - val_loss: 1.2938 - val_accuracy: 0.3820\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 1s 39ms/step - loss: 0.0959 - accuracy: 0.9708 - val_loss: 2.2268 - val_accuracy: 0.2590\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 1s 39ms/step - loss: 0.0547 - accuracy: 0.9869 - val_loss: 2.7431 - val_accuracy: 0.2847\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 1s 38ms/step - loss: 0.0322 - accuracy: 0.9945 - val_loss: 2.6542 - val_accuracy: 0.3590\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 1s 38ms/step - loss: 0.0199 - accuracy: 0.9975 - val_loss: 3.0295 - val_accuracy: 0.3444\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 1s 37ms/step - loss: 0.0126 - accuracy: 0.9991 - val_loss: 2.8662 - val_accuracy: 0.3903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://c084051c-c55f-4af0-a6c1-189bdf64ac4a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://c084051c-c55f-4af0-a6c1-189bdf64ac4a/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can find trained model in trained_models\n",
      "============================END OF PIPELINE============================\n"
     ]
    }
   ],
   "source": [
    "train_SA.run_sa_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After evaluating the performance of the different models, our selection compared the scores across the 2 models. From the output we can see that LSTM performed better in all aspects - Accuracy, precision, ROC AUC, Recall and F1 score. Therefore, LSTM is deemed as the best model for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Data Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment_analysis.train import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================READ RAW DATA=======================\n",
      "=======================LOWERCASE TEXT=======================\n",
      "========================TOKENIZE TEXT=======================\n",
      "=====================REMOVE PUNCTUATION=====================\n",
      "======================REMOVE STOPWORDS======================\n",
      "=====================REMOVE SHORT WORDS=====================\n",
      "==================CONVERT AMAZON.COM TOKENS=================\n",
      "=====================REMOVE CONTRACTIONS====================\n",
      "=====================REMOVE PUNCTUATION=====================\n",
      "========================REMOVE DIGITS=======================\n",
      "======================LEMMATIZE TOKENS======================\n",
      "======================REMOVE DUPLICATES=====================\n",
      "==================DATA PREPROCESSING DONE===================\n",
      "=======================ORIGINAL TEXT========================\n",
      "0    this is a very healthy dog food. good for thei...\n",
      "1    i've been very pleased with the natural balanc...\n",
      "2    before i was educated about feline nutrition, ...\n",
      "3    my holistic vet recommended this, along with a...\n",
      "4    i bought this coffee because its much cheaper ...\n",
      "Name: Text, dtype: object\n",
      "=====================PREPROCESSED TOKENS====================\n",
      "0    [dog, require, amount, healthy, every, good, f...\n",
      "1    [dog, balance, large, kibble, issue, someone, ...\n",
      "2    [feed, educate, canned, old, good, recently, d...\n",
      "3    [less, benefit, health, vet, find, prefer, cat...\n",
      "4    [expect, less, totally, good, taste, introduci...\n",
      "Name: cleaned, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyangyi/Documents/GitHub/DSA4263_T00/src/sentiment_analysis/prep/preprocess.py:349: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df.loc[:,'cleaned2'] = final_df.loc[:,'cleaned'].apply(lambda x: ' '.join(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 1s 5ms/step\n",
      "Predicted csv has been generated\n"
     ]
    }
   ],
   "source": [
    "evaluate.get_score(\"../datasets/reviews_test.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_TM.run_tm_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

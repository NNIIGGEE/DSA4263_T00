{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdfd22a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/niiggee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "\n",
    "# NLTK imports\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f399d537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/niiggee/Desktop/SCHOOLWORK/Y4S2/DSA4265/Codes'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4b41358",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARROW_PRE_0_15_IPC_FORMAT=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce4f27",
   "metadata": {},
   "source": [
    "## data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b69b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/Users/niiggee/Desktop/SCHOOLWORK/Y4S2/DSA4265/datasets/\"\n",
    "csv_path = input_path + \"clean_21_march.csv\"\n",
    "AFIN_path = input_path + \"AFINN-en.json\"\n",
    "INPUT_test = input_path + \"en.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df_en = pd.read_csv(INPUT_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec5b9cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>18/6/21</td>\n",
       "      <td>This is a very healthy dog food. Good for thei...</td>\n",
       "      <td>['healthy', 'dog', 'food', 'good', 'digestion'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>7/7/21</td>\n",
       "      <td>I've been very pleased with the Natural Balanc...</td>\n",
       "      <td>['pleased', 'natural', 'balance', 'dog', 'food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>18/6/21</td>\n",
       "      <td>Before I was educated about feline nutrition, ...</td>\n",
       "      <td>['educated', 'feline', 'nutrition', 'allowed',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>7/7/21</td>\n",
       "      <td>My holistic vet recommended this, along with a...</td>\n",
       "      <td>['holistic', 'vet', 'recommended', 'this', 'al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>1/7/21</td>\n",
       "      <td>I bought this coffee because its much cheaper ...</td>\n",
       "      <td>['bought', 'coffee', 'much', 'cheaper', 'ganoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5439</th>\n",
       "      <td>5439</td>\n",
       "      <td>negative</td>\n",
       "      <td>26/2/21</td>\n",
       "      <td>This is an okay gift box, only if you like med...</td>\n",
       "      <td>['okay', 'gift', 'box', 'like', 'mediocre', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>5440</td>\n",
       "      <td>negative</td>\n",
       "      <td>18/12/19</td>\n",
       "      <td>It looks llike I just walked into a raw deal. ...</td>\n",
       "      <td>['look', 'llike', 'walked', 'raw', 'deal', 'it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5441</th>\n",
       "      <td>5441</td>\n",
       "      <td>negative</td>\n",
       "      <td>19/1/20</td>\n",
       "      <td>Thank god that i tasted the metal before i swa...</td>\n",
       "      <td>['thank', 'god', 'tasted', 'metal', 'swallowed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5442</th>\n",
       "      <td>5442</td>\n",
       "      <td>negative</td>\n",
       "      <td>13/9/20</td>\n",
       "      <td>This product was very good when I began buying...</td>\n",
       "      <td>['product', 'good', 'began', 'buying', 'lately...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5443</th>\n",
       "      <td>5443</td>\n",
       "      <td>negative</td>\n",
       "      <td>10/7/20</td>\n",
       "      <td>Once again, Paragon has disappointed with this...</td>\n",
       "      <td>['again', 'paragon', 'disappointed', 'flavor',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5444 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Sentiment      Time  \\\n",
       "0              0  positive   18/6/21   \n",
       "1              1  positive    7/7/21   \n",
       "2              2  positive   18/6/21   \n",
       "3              3  positive    7/7/21   \n",
       "4              4  positive    1/7/21   \n",
       "...          ...       ...       ...   \n",
       "5439        5439  negative   26/2/21   \n",
       "5440        5440  negative  18/12/19   \n",
       "5441        5441  negative   19/1/20   \n",
       "5442        5442  negative   13/9/20   \n",
       "5443        5443  negative   10/7/20   \n",
       "\n",
       "                                                   Text  \\\n",
       "0     This is a very healthy dog food. Good for thei...   \n",
       "1     I've been very pleased with the Natural Balanc...   \n",
       "2     Before I was educated about feline nutrition, ...   \n",
       "3     My holistic vet recommended this, along with a...   \n",
       "4     I bought this coffee because its much cheaper ...   \n",
       "...                                                 ...   \n",
       "5439  This is an okay gift box, only if you like med...   \n",
       "5440  It looks llike I just walked into a raw deal. ...   \n",
       "5441  Thank god that i tasted the metal before i swa...   \n",
       "5442  This product was very good when I began buying...   \n",
       "5443  Once again, Paragon has disappointed with this...   \n",
       "\n",
       "                                                cleaned  \n",
       "0     ['healthy', 'dog', 'food', 'good', 'digestion'...  \n",
       "1     ['pleased', 'natural', 'balance', 'dog', 'food...  \n",
       "2     ['educated', 'feline', 'nutrition', 'allowed',...  \n",
       "3     ['holistic', 'vet', 'recommended', 'this', 'al...  \n",
       "4     ['bought', 'coffee', 'much', 'cheaper', 'ganoc...  \n",
       "...                                                 ...  \n",
       "5439  ['okay', 'gift', 'box', 'like', 'mediocre', 'c...  \n",
       "5440  ['look', 'llike', 'walked', 'raw', 'deal', 'it...  \n",
       "5441  ['thank', 'god', 'tasted', 'metal', 'swallowed...  \n",
       "5442  ['product', 'good', 'began', 'buying', 'lately...  \n",
       "5443  ['again', 'paragon', 'disappointed', 'flavor',...  \n",
       "\n",
       "[5444 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en = df_en\n",
    "df_10 = df\n",
    "df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a93306a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\'educated\\', \\'feline\\', \\'nutrition\\', \\'allowed\\', \\'cat\\', \\'become\\', \\'addicted\\', \\'dry\\', \\'cat\\', \\'food\\', \\'always\\', \\'offered\\', \\'canned\\', \\'dry\\', \\'wish\\', \\'would\\', \\'fed\\', \\'premium\\', \\'quality\\', \\'canned\\', \\'food\\', \\'limited\\', \\'dry\\', \\'food\\', \\'two\\', \\'year\\', \\'old\\', \\'cat\\', \\'two\\', \\'year\\', \\'old\\', \\'cat\\', \\'good\\', \\'quality\\', \\'dry\\', \\'food\\', \\'eat\\', \\'wellness\\', \\'innova\\', \"innova\\'s\", \\'manufacturer\\', \\'recently\\', \\'purchased\\', \\'procter\\', \\'gamble\\', \\'began\\', \\'looking\\', \\'replacement\\', \\'offering\\', \\'several\\', \\'sample\\', \\'from\\', \\'local\\', \\'holistic\\', \\'pet\\', \\'store\\', \\'holistic\\', \\'select\\', \\'one\\', \\'other\\', \\'usual\\', \\'wellness\\', \\'innova\\', \\'would\\', \\'eat\\', \\'finicky\\', \\'cat\\', \\'recommend\\', \\'trying\\', \\'holistic\\', \\'select\\', \\'good\\', \\'quality\\', \\'food\\', \\'palatable\\', \\'finicky\\', \\'eater\\']'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_10.iloc[2]['cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1919fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_10['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b8d8e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopWords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8f211",
   "metadata": {},
   "source": [
    "## cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08a5e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apwords(sentence):\n",
    "#     filtered_sentence = []\n",
    "#     tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#     token_bag = tokenizer.tokenize(sentence)\n",
    "    \n",
    "#     for w in token_bag:\n",
    "#         if w in stopWords:\n",
    "#             continue\n",
    "#         if type(w) != str:\n",
    "#             print(w)\n",
    "#             continue\n",
    "            \n",
    "#         filtered_sentence.append(f'{w}')\n",
    "#     return filtered_sentence\n",
    "\n",
    "# addwords = lambda x: apwords(x)\n",
    "\n",
    "# df_10['split_text'] = df_10['Text'].apply(addwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e504144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10 = df_10.dropna(how='any')\n",
    "# df_10 = df_10.drop(columns = 'Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "918fbfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10.to_csv('df_10.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0347f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark_csv = \"df_10.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25729f4",
   "metadata": {},
   "source": [
    "## SPARK env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b76f9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/26 16:33:15 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "#!pip install pyspark findspark\n",
    "import findspark\n",
    "findspark.find()\n",
    "from pyspark.sql.functions import monotonically_increasing_id, col, concat_ws\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.functions import lower, col \n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType\n",
    "\n",
    "LANG = \"en\"\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Lexicon_3\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ebacca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b48a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df = spark.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5814133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Unnamed: 0: long (nullable = true)\n",
      " |-- Sentiment: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      " |-- cleaned: string (nullable = true)\n",
      "\n",
      "23/03/26 16:33:56 WARN TaskSetManager: Stage 2 contains a task of very large size (3708 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/26 16:34:00 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 2 (TID 2): Attempting to kill Python Worker\n",
      "+----------+---------+-------+--------------------+--------------------+\n",
      "|Unnamed: 0|Sentiment|   Time|                Text|             cleaned|\n",
      "+----------+---------+-------+--------------------+--------------------+\n",
      "|         0| positive|18/6/21|This is a very he...|['healthy', 'dog'...|\n",
      "|         1| positive| 7/7/21|I've been very pl...|['pleased', 'natu...|\n",
      "|         2| positive|18/6/21|Before I was educ...|['educated', 'fel...|\n",
      "+----------+---------+-------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "s_df.printSchema()\n",
    "s_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d19c9ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/26 16:34:00 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 4:>                                                          (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "AFINN_DICT = spark.read.json(AFIN_path, multiLine=True)\n",
    "AFINN_DICT = dict(zip(AFINN_DICT.schema.names, *AFINN_DICT.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1da19319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/26 16:34:13 WARN TaskSetManager: Stage 5 contains a task of very large size (3708 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+--------------------+--------------------+----------+\n",
      "|Unnamed: 0|Sentiment|   Time|                Text|             cleaned|word_score|\n",
      "+----------+---------+-------+--------------------+--------------------+----------+\n",
      "|         0| positive|18/6/21|This is a very he...|['healthy', 'dog'...| [2, 0, 0]|\n",
      "|         0| positive|18/6/21|This is a very he...|['healthy', 'dog'...| [0, 0, 1]|\n",
      "|         0| positive|18/6/21|This is a very he...|['healthy', 'dog'...| [0, 0, 1]|\n",
      "|         0| positive|18/6/21|This is a very he...|['healthy', 'dog'...| [3, 0, 0]|\n",
      "|         0| positive|18/6/21|This is a very he...|['healthy', 'dog'...| [0, 0, 1]|\n",
      "|         0| positive|18/6/21|This is a very he...|['healthy', 'dog'...| [0, 0, 1]|\n",
      "|         0| positive|18/6/21|This is a very he...|['healthy', 'dog'...| [3, 0, 0]|\n",
      "|         0| positive|18/6/21|This is a very he...|['healthy', 'dog'...| [0, 0, 1]|\n",
      "|         0| positive|18/6/21|This is a very he...|['healthy', 'dog'...| [0, 0, 1]|\n",
      "|         0| positive|18/6/21|This is a very he...|['healthy', 'dog'...| [0, 0, 1]|\n",
      "+----------+---------+-------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, explode, first\n",
    "from ast import literal_eval\n",
    "\n",
    "format_text = udf(lambda text: literal_eval(text), ArrayType(StringType()))\n",
    "formatted_data = s_df.withColumn(\"tokens\", format_text(col(\"cleaned\")))\n",
    "\n",
    "def calculate_score(word):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    neu = 0\n",
    "  \n",
    "    if word in AFINN_DICT:\n",
    "        score = AFINN_DICT[word]\n",
    "        if (score > 0):\n",
    "            return score, neg, neu\n",
    "        elif (score < 0):\n",
    "            return pos, -score, neu\n",
    "        else:\n",
    "            return pos, neg, 1\n",
    "    else:\n",
    "        return pos, neg, 1\n",
    "\n",
    "word_score = udf(lambda arr: [calculate_score(x) for x in arr], ArrayType(ArrayType(IntegerType())))\n",
    "\n",
    "formatted_data = formatted_data.withColumn(\"test\", word_score(col(\"tokens\")))\n",
    "formatted_data = formatted_data.withColumn(\"word_score\", explode(formatted_data.test)).drop(\"test\", \"tokens\")\n",
    "formatted_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4985b343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/26 16:34:41 WARN TaskSetManager: Stage 6 contains a task of very large size (3708 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 6:>                                                          (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|Unnamed: 0|          score|\n",
      "+----------+---------------+\n",
      "|         0| [8.0,0.0,12.0]|\n",
      "|         1|[10.0,2.0,25.0]|\n",
      "|         2|[15.0,1.0,69.0]|\n",
      "|         3|[13.0,3.0,35.0]|\n",
      "|         4| [7.0,0.0,26.0]|\n",
      "|         5|[11.0,0.0,20.0]|\n",
      "|         6| [6.0,0.0,13.0]|\n",
      "|         7| [9.0,0.0,17.0]|\n",
      "|         8| [6.0,0.0,13.0]|\n",
      "|         9| [8.0,0.0,14.0]|\n",
      "+----------+---------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "23/03/26 16:34:42 WARN TaskSetManager: Stage 9 contains a task of very large size (3708 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5444"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.functions import array_to_vector\n",
    "from pyspark.ml.stat import Summarizer\n",
    "\n",
    "with_vec = formatted_data.withColumn(\"word_score\", array_to_vector(\"word_score\"))\n",
    "with_vec = with_vec.groupBy(\"Unnamed: 0\").agg(Summarizer.sum(with_vec.word_score).alias(\"score\"))\n",
    "with_vec.show(10)\n",
    "with_vec.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9037d16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "def calculate_sentiment(arr):\n",
    "  pos = arr[0]\n",
    "  neg = arr[1]\n",
    "  if (pos > neg):\n",
    "    return \"positive\"\n",
    "  elif (pos < neg):\n",
    "    return \"negative\"\n",
    "  else:\n",
    "    return \"neutral\"\n",
    "\n",
    "sentence_sentiment = udf(lambda arr: calculate_sentiment(arr), StringType())\n",
    "\n",
    "sentiments = s_df.join(with_vec, s_df[\"Unnamed: 0\"] == with_vec[\"Unnamed: 0\"]).select(col(\"cleaned\").alias(\"cleaned\"), \n",
    "                                                                  sentence_sentiment(col(\"score\")).alias(\"Sentiment\"), \n",
    "                                                                  col(\"Time\").alias(\"Time\"))\n",
    "\n",
    "# sentiments = data.join(with_vec, data._c0 == with_vec._c0).select(col(\"text\").alias(\"Text\"), \n",
    "#                                                                   sentence_sentiment(col(\"score\")).alias(\"Sentiment\"), \n",
    "#                                                                   col(\"lang\").alias(\"Lang\"), \n",
    "#                                                                   col(\"created_at\").alias(\"Created_at\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d6ff53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont show sentiments cause ur CPU will die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e857900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/26 16:36:08 WARN TaskSetManager: Stage 15 contains a task of very large size (3708 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/03/26 16:36:08 WARN TaskSetManager: Stage 16 contains a task of very large size (3708 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5444"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ca5b38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/26 16:36:10 WARN TaskSetManager: Stage 24 contains a task of very large size (3708 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/03/26 16:36:10 WARN TaskSetManager: Stage 25 contains a task of very large size (3708 KiB). The maximum recommended task size is 1000 KiB.\n",
      "+--------------------+---------+-------+\n",
      "|             cleaned|Sentiment|   Time|\n",
      "+--------------------+---------+-------+\n",
      "|['healthy', 'dog'...| positive|18/6/21|\n",
      "|['pleased', 'natu...| positive| 7/7/21|\n",
      "|['educated', 'fel...| positive|18/6/21|\n",
      "|['holistic', 'vet...| positive| 7/7/21|\n",
      "|['bought', 'coffe...| positive| 1/7/21|\n",
      "|['like', 'people'...| positive| 7/7/21|\n",
      "|['good', 'tasting...| positive|23/7/21|\n",
      "|['grande', 'item'...| positive|20/7/21|\n",
      "|['ordered', 'prod...| positive|19/7/21|\n",
      "|['stuff', 'great'...| positive|18/6/21|\n",
      "+--------------------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiments.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a376a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/26 16:37:48 WARN TaskSetManager: Stage 30 contains a task of very large size (3708 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/03/26 16:37:48 WARN TaskSetManager: Stage 31 contains a task of very large size (3708 KiB). The maximum recommended task size is 1000 KiB.\n",
      "+---------+\n",
      "|Sentiment|\n",
      "+---------+\n",
      "| positive|\n",
      "|  neutral|\n",
      "| negative|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiments.select('Sentiment').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e363dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_FOLDER = os.path.join(\"/Users/niiggee/Desktop/SCHOOLWORK/Y4S2/DSA4265/\", \"temp\")\n",
    "\n",
    "sentiments.write.format(\"csv\").option(\"header\", \"true\").save(\"/Users/niiggee/Desktop/SCHOOLWORK/Y4S2/DSA4265/temp\")\n",
    "combined_files = spark.read.option('header', 'true').csv(TEMP_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
